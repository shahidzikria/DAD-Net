{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo0to5fMvZj_"
   },
   "source": [
    "# <font color=green><center>DAD-Net: Classification Of Alzheimerâ€™s Disease Using ADASYN Oversampling Technique and Optimized Neural Network</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ANKLFDYvZkD"
   },
   "source": [
    "### **<font color=purple> packages that need to install to run this code </font>**\n",
    "- pip install <font color=red>**tensrflow**</font> || in case of GPU use pip install <font color=red>**tensrflow-gpu**</font>\n",
    "- pip install <font color=red>**imblearn**</font>\n",
    "- pip install <font color=red>**tensorflow-addons**</font>\n",
    "- pip install <font color=red>**matplotlib**</font>\n",
    "- pip install <font color=red>**seaborn**</font>\n",
    "- pip install <font color=red>**keras**</font>\n",
    "- pip install <font color=red>**scikit-learn**</font>\n",
    "\n",
    "### **Dataset [Link](https://www.kaggle.com/datasets/shahidzikria/alz-dataset)**\n",
    "#### File modified to run on colab\n",
    "##### **Follow the below instructions**\n",
    "- Instructions to add dataset in colab from kaggle [Link](https://www.kaggle.com/general/74235)\n",
    "- download dataset in your current directory or another and carefully add path in the **WORKING_DIRECTORY** variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzH-EVvYzWx6"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install imblearn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keGAVEuEvZkE"
   },
   "source": [
    "### <font color=orange> Importing Libraries </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRiiRLawvZkF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#   Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#   DataGenerator to read images and rescale images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#   count each class samples\n",
    "from collections import Counter\n",
    "\n",
    "#   callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#   evaluate precison recall and f1-score of each class of model\n",
    "from sklearn.metrics import classification_report\n",
    "#   Show performance of a classification model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#   Different layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Softmax\n",
    "\n",
    "# split dataset to train, validation and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#   callbacks\n",
    "from keras import callbacks\n",
    "\n",
    "#   ADASYN from imblance library\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "#   Optimizer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xk-5R8TvZkH"
   },
   "source": [
    "### <font color=orange> Define directory of dataset & Classes names </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TImlZzYtvZkI"
   },
   "outputs": [],
   "source": [
    "## Set Path Here before running the code\n",
    "WORKING_DIRECTORY =  r\"C:\\dataset\"\n",
    "\n",
    "##  Name of classes \n",
    "CLASSES = ['Mild-Demented',\n",
    "           'Moderate-Demented',\n",
    "           'Non-Demented',\n",
    "           'VeryMild-Demented']\n",
    "\n",
    "IMG_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3ULowyBvZkJ"
   },
   "source": [
    "### <font color=orange> Load Images, Rescale Images, and seperate from data generator & Label One Hot encoding </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeDJMOVmvZkK"
   },
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "## Images rescaling\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "#   Load images by resizing and shuffling randomly\n",
    "train_dataset = datagen.flow_from_directory(WORKING_DIRECTORY, target_size=(IMG_SIZE, IMG_SIZE),batch_size=6400, shuffle=True)\n",
    "\n",
    "### Seperate Dataset from  Data Genrator\n",
    "X, y = train_dataset.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5Ea-fPcvZkL"
   },
   "outputs": [],
   "source": [
    "samples_before = len(X)\n",
    "print(\"Images shape :\\t\", X.shape)\n",
    "print(\"Labels shape :\\t\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lut1yE6WvZkM"
   },
   "outputs": [],
   "source": [
    "#   Number of samples in classes \n",
    "print(\"Number of samples in each class:\\t\", sorted(Counter(np.argmax(y, axis=1)).items()))\n",
    "\n",
    "#   class labels as per indices\n",
    "print(\"Classes Names according to index:\\t\", train_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRPom6TCvZkM"
   },
   "source": [
    "### <font color=orange> Show some random samples from the origional dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoaygwE1vZkN"
   },
   "outputs": [],
   "source": [
    "#   show some samples from the dataset randomly\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "rows = 4\n",
    "columns = 4\n",
    "\n",
    "for i in range(rows * columns):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    num = random.randint(0, len(X)-1 )\n",
    "    plt.imshow(X[num])\n",
    "    plt.axis('off')\n",
    "    plt.title(CLASSES[(np.argmax(y[num]))], fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxTk-4vRvZkO"
   },
   "source": [
    "### <font color=orange> Apply ADASYN Algorithm to OverSample the dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOVZSTJ5vZkO"
   },
   "outputs": [],
   "source": [
    "#   reshaping the images to 1D\n",
    "X = X.reshape(-1, IMG_SIZE * IMG_SIZE * 3)\n",
    "\n",
    "#   Oversampling method to remove imbalance class problem\n",
    "X, y = ADASYN().fit_resample(X, y)\n",
    "\n",
    "#   reshape images to images size of 208, 176, 3\n",
    "X = X.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "samples_after = len(X)\n",
    "print(\"Number of samples after SMOTETomek :\\t\", sorted(Counter(np.argmax(y, axis=1)).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibY5cLtBvZkO"
   },
   "source": [
    "### <font color=orange> Show some random samples from the Generated dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmJ2NMhKvZkP"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "rows = 4\n",
    "columns = 4\n",
    "\n",
    "for i in range(rows * columns):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    num = random.randint(samples_before, samples_after - 1 )\n",
    "    plt.imshow(X[num])\n",
    "    plt.axis('off')\n",
    "    plt.title(CLASSES[(np.argmax(y[num]))], fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQjFheR9vZkP"
   },
   "source": [
    "### <font color=orange> Splitting dataset for Training, Validation & Testing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3N2-3D_vZkQ"
   },
   "outputs": [],
   "source": [
    "#   10% split to validation and 90% split to train set\n",
    "X_train, x_val, y_train, y_val = train_test_split(X,y, test_size = 0.1)\n",
    "\n",
    "#   10% split to test from 90% of train and 80% remains in train set\n",
    "X_train, x_test, y_train, y_test = train_test_split(X_train,y_train, test_size = 0.1)\n",
    "\n",
    "# Number of samples after train test split\n",
    "print(\"Number of samples after splitting into Training, validation & test set\\n\")\n",
    "\n",
    "print(\"Train     \\t\",sorted(Counter(np.argmax(y_train, axis=1)).items()))\n",
    "print(\"Validation\\t\",sorted(Counter(np.argmax(y_val, axis=1)).items()))\n",
    "print(\"Test      \\t\",sorted(Counter(np.argmax(y_test, axis=1)).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5o9qGE8dvZkQ"
   },
   "outputs": [],
   "source": [
    "#   to free memeory we don't need this one as we split our data\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyAKiuymvZkQ"
   },
   "source": [
    "### <font color=orange> Model Architecture </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huhbFypHvZkR"
   },
   "outputs": [],
   "source": [
    "from keras.initializers import LecunUniformV2\n",
    "init = LecunUniformV2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "model.add(Conv2D(8, 3, padding=\"same\", kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16, 3, padding=\"same\", kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, 3, padding=\"same\", kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=init))\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(Dense(4, kernel_initializer=init))\n",
    "model.add(Softmax())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyzdrIuevZkR"
   },
   "source": [
    "### <font color=orange> Compiling the Model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgIjqz5YvZkR"
   },
   "outputs": [],
   "source": [
    "### Model Compilation\n",
    "model.compile(\n",
    "    optimizer = RMSprop(learning_rate=0.0001), \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(name='loss'), \n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='acc'), \n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tfa.metrics.F1Score(num_classes=4),\n",
    "        tf.metrics.Precision(name=\"precision\"),\n",
    "        tf.metrics.Recall(name=\"recall\") ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOUmPfY6vZkS"
   },
   "source": [
    "### <font color=orange> Defining CALLBACKS to reduce Learning Rate </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgk6sIc8vZkS"
   },
   "outputs": [],
   "source": [
    "# callbacks used in model to perform well\n",
    "rop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=2)\n",
    "\n",
    "CALLBACKS = [rop_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHMms8TGvZkS"
   },
   "source": [
    "### <font color=orange> Training of the Model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bURNnD5FvZkT"
   },
   "outputs": [],
   "source": [
    "#   declare to run on small gpu create batch sizes of images\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "#   defining batch size\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(valAug.flow(X_train, y_train, batch_size=batch_size, shuffle = True),\n",
    "steps_per_epoch=len(X_train) // batch_size,\n",
    "validation_data=valAug.flow(x_val, y_val, batch_size=batch_size, shuffle = True),\n",
    "validation_steps=len(x_test) // batch_size,\n",
    "epochs= 30,\n",
    "batch_size=batch_size,\n",
    "callbacks = CALLBACKS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q21wep3VvZkT"
   },
   "source": [
    "### <font color=orange> Evaluation of Model with the Test data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcXw_wuQvZkT"
   },
   "outputs": [],
   "source": [
    "### Evaluate Model\n",
    "test_scores = model.evaluate(x_test, y_test, batch_size = 32)\n",
    "\n",
    "\n",
    "print(\"\\n\\nTesting Loss : \\t\\t {0:0.6f}\".format(test_scores[0] ))\n",
    "print(\"Testing Accuracy : \\t {0:0.6f} %\".format(test_scores[1] * 100))\n",
    "print(\"Testing AC : \\t\\t {0:0.6f} %\".format(test_scores[2] * 100))\n",
    "print(\"Testing F1-Score : \\t {0:0.6f} %\".format(\n",
    "    ((test_scores[3][0] + test_scores[3][1] + test_scores[3][2] + test_scores[3][3])/4) * 100))\n",
    "print(\"Testing Precision : \\t {0:0.6f} %\".format(test_scores[4] * 100))\n",
    "print(\"Testing Recall : \\t {0:0.6f} %\".format(test_scores[5] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0dEGvdYvZkT"
   },
   "source": [
    "### <font color=orange> Model Training graphs </font>\n",
    "- Accuracy\n",
    "- Loss\n",
    "- AUC\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YW0SPtaYvZkU"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], 'b')\n",
    "plt.plot(history.history['val_acc'], 'g')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeHauaquvZkU"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], 'b')\n",
    "plt.plot(history.history['val_loss'], 'g')\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyXscunhvZkU"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['auc'], 'b')\n",
    "plt.plot(history.history['val_auc'], 'g')\n",
    "plt.title(\"Model AUC\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:54:56.423972Z",
     "iopub.status.busy": "2022-04-21T23:54:56.423371Z",
     "iopub.status.idle": "2022-04-21T23:54:58.0292Z",
     "shell.execute_reply": "2022-04-21T23:54:58.028308Z",
     "shell.execute_reply.started": "2022-04-21T23:54:56.423933Z"
    },
    "id": "ALsEPVMkvZkU"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['precision'], 'b')\n",
    "plt.plot(history.history['val_precision'], 'g')\n",
    "plt.title(\"Model Precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-TZnh4JvZkV"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['recall'], 'b')\n",
    "plt.plot(history.history['val_recall'], 'g')\n",
    "plt.title(\"Model Recall\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:54:58.982393Z",
     "iopub.status.busy": "2022-04-21T23:54:58.981768Z",
     "iopub.status.idle": "2022-04-21T23:54:59.26636Z",
     "shell.execute_reply": "2022-04-21T23:54:59.26569Z",
     "shell.execute_reply.started": "2022-04-21T23:54:58.982348Z"
    },
    "id": "euJR0rK_vZkV"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title(\"Model F1-Score\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un9qqbRuvZkV"
   },
   "source": [
    "### <font color=orange> Test set Evaluation </font>\n",
    "- Classification Report\n",
    "- Confusion Matrix\n",
    "- ROC Curve\n",
    "- Extension ROC Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:55:05.464239Z",
     "iopub.status.busy": "2022-04-21T23:55:05.463988Z",
     "iopub.status.idle": "2022-04-21T23:55:11.572243Z",
     "shell.execute_reply": "2022-04-21T23:55:11.571516Z",
     "shell.execute_reply.started": "2022-04-21T23:55:05.464211Z"
    },
    "id": "aMPYvN5dvZkW"
   },
   "outputs": [],
   "source": [
    "pred_labels = model.predict(x_test, batch_size=32)\n",
    "\n",
    "def roundoff(arr):\n",
    "    arr[np.argwhere(arr != arr.max())] = 0\n",
    "    arr[np.argwhere(arr == arr.max())] = 1\n",
    "    return arr\n",
    "\n",
    "for labels in pred_labels:\n",
    "    labels = roundoff(labels)\n",
    "\n",
    "print(classification_report(y_test, pred_labels, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:57:46.714967Z",
     "iopub.status.busy": "2022-04-21T23:57:46.714699Z",
     "iopub.status.idle": "2022-04-21T23:57:47.040205Z",
     "shell.execute_reply": "2022-04-21T23:57:47.039518Z",
     "shell.execute_reply.started": "2022-04-21T23:57:46.714938Z"
    },
    "id": "mEJbBGzIvZkW"
   },
   "outputs": [],
   "source": [
    "pred_ls = np.argmax(pred_labels, axis=1)\n",
    "test_ls = np.argmax(y_test, axis=1)\n",
    "\n",
    "conf_arr = confusion_matrix(test_ls, pred_ls)\n",
    "\n",
    "plt.figure(figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels= CLASSES, yticklabels=CLASSES)\n",
    "\n",
    "plt.title('Confusion Matrix of Model', fontweight='bold', fontsize=14.0)\n",
    "plt.xlabel('Predictions', fontweight='bold', fontsize=13)\n",
    "plt.ylabel('Ground Truth', fontweight='bold', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:55:47.647003Z",
     "iopub.status.busy": "2022-04-21T23:55:47.646745Z",
     "iopub.status.idle": "2022-04-21T23:55:47.660648Z",
     "shell.execute_reply": "2022-04-21T23:55:47.659893Z",
     "shell.execute_reply.started": "2022-04-21T23:55:47.646975Z"
    },
    "id": "gEHWMSykvZkW"
   },
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_labels[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_labels.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr[2],\n",
    "    tpr[2],\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.4f)\" % roc_auc[2])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic \")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:55:49.689918Z",
     "iopub.status.busy": "2022-04-21T23:55:49.689416Z",
     "iopub.status.idle": "2022-04-21T23:55:49.991823Z",
     "shell.execute_reply": "2022-04-21T23:55:49.991148Z",
     "shell.execute_reply.started": "2022-04-21T23:55:49.689881Z"
    },
    "id": "69YPbkP4vZkX"
   },
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.4f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.4f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.4f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TROVxdnKvZkX"
   },
   "source": [
    "### <font color=orange> Saving Model for Future Use </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T23:54:50.547225Z",
     "iopub.status.busy": "2022-04-21T23:54:50.546962Z",
     "iopub.status.idle": "2022-04-21T23:54:52.26482Z",
     "shell.execute_reply": "2022-04-21T23:54:52.263993Z",
     "shell.execute_reply.started": "2022-04-21T23:54:50.547191Z"
    },
    "id": "OVHqhlaavZkX"
   },
   "outputs": [],
   "source": [
    "#    To save the model in the current directory\n",
    "model.save(\".\\\\model.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "keGAVEuEvZkE",
    "6Xk-5R8TvZkH",
    "E3ULowyBvZkJ",
    "KRPom6TCvZkM",
    "yxTk-4vRvZkO",
    "ibY5cLtBvZkO",
    "JQjFheR9vZkP",
    "GyAKiuymvZkQ",
    "AyzdrIuevZkR",
    "hOUmPfY6vZkS",
    "MHMms8TGvZkS",
    "q21wep3VvZkT",
    "n0dEGvdYvZkT",
    "Un9qqbRuvZkV",
    "TROVxdnKvZkX"
   ],
   "name": "ADDNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4a279c040b21a8a17e6b0e4617228f81a21133805a5d7bd87a8197b0c3bf407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
